{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45ef0dd0-fa4b-454a-9fad-922c84d8b5b3",
   "metadata": {},
   "source": [
    "# Dask for large scale computations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a914b445-abdd-4c68-a2b4-396a389282e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## What is [Dask](https://www.dask.org/)?\n",
    "\n",
    "How does Dask describe Dask:\n",
    "\n",
    "> Dask is a parallel and distributed computing library that scales the existing Python and PyData ecosystem.\n",
    ">\n",
    "> Dask can scale up to your full laptop capacity and out to a cloud cluster.\n",
    "\n",
    "Source: [Dask Tutorial](https://tutorial.dask.org/00_overview.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6721517f-72fa-4a78-810a-ae2c551ea375",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Core advantages of Dask\n",
    "\n",
    "As a brief overview, Dask offers Dask Collections, Dask Cluster and several additional packages such as Dask-ML, Dask-sql.\n",
    "\n",
    "Dask Collections represent the part of the library dedicated to multi-core, distributed execution on larger-than-memory datasets. This is ultimately the key reason to use Dask, your dataset is larger than the memory on your single machine but you'd still like to work with the data as you would if you were using NumPy or Pandas. \n",
    "\n",
    "The high-level API includes [Dask Array](https://docs.dask.org/en/stable/array.html), a subset of NumPy's `ndarray` interface, [Dask Bag](https://docs.dask.org/en/stable/bag.html), an implementation of generic Python operations like `map`, `filter`, `groupby`, and [Dask DataFrame](https://docs.dask.org/en/stable/dataframe.html), a subset of Panda's `DataFrame` and `Series` interface. \n",
    "\n",
    "> A low-level API, Dask Delayed and Dask Futures, is also available but beyond the scope of this tutorial.\n",
    "\n",
    "The advantage of the approach taken by Dask is that if you are familiar with NumPy's `ndarray` or Panda's `DataFrame`, you can get started using Dask Array or Dask DataFrame rather quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735d78af-b6c1-444b-a2ab-d0713f91e05f",
   "metadata": {},
   "source": [
    "## What is [Dask Gateway](https://gateway.dask.org/)?\n",
    "\n",
    "**Dask-Gateway comes standard with your Nebari deployment.**\n",
    "\n",
    "Although Dask can be used on a single machine, Dask Cluster represent the part of the library dedicated to actually administering your workload to a distrubuted cluster of machines. Dask can be setup to run on a variety of backend clusters, including Kubernetes, Docker, HPC, YARN/Hadoop, Dask-Gateway and more.\n",
    "\n",
    "For the purposes of this Nebari tutorial, when we refer to Dask running on a distributed cluster, we mean connecting to Dask-Gateway.\n",
    "\n",
    "This means that users with access to Dask-Gateway (more on user permissions in a later notebook) simply need to connect to the gateway to submit their workloads to the Dask cluster. See either of the links at the bottom of this page for a concrete example of how this done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ebfdd0-9cff-47f8-a42d-0adf1a3b6815",
   "metadata": {},
   "source": [
    "## When is Dask used?\n",
    "\n",
    "Dask Collections, such as Dask DataFrame, and Dask-Gateway are used together when you have a dataset that is larger than the memory of your local machine (or the Nebari JupyterLab server you are running on) but you still need to load it and manipulate it some way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2097b48f-4607-49d0-a118-923867f60813",
   "metadata": {},
   "source": [
    "## üëÄ Watch this...\n",
    "\n",
    "Here we run through a basic example of how to use Dask-Gateway in Nebari: [finance_examples/02_dask_gateway_adaptive_scaling.ipynb](./finance_examples/02_dask_gateway_adaptive_scaling.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a8ca5b-2c5c-41a7-a157-5a4e2d338a49",
   "metadata": {},
   "source": [
    "---\n",
    "## üëè Next:\n",
    "* [03_managing_environments](./03_managing_environments.ipynb)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21858540-4ff8-4780-8d7e-8c3bedfa137d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "filesystem-filesystem-dask",
   "language": "python",
   "name": "conda-env-filesystem-filesystem-dask-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
